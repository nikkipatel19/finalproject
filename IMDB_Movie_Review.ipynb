{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 – IMDB MOVIE REVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text Data(Remove punctuation, Perform Tokenization, Remove stopwords and Lemmatize/Stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nikipatel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/nikipatel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nikipatel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I got this one a few weeks ago and love it! It...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      I thought this was a wonderful way to spend ti...  positive\n",
       "1      Probably my all-time favorite movie, a story o...  positive\n",
       "2      I sure would like to see a resurrection of a u...  positive\n",
       "3      This show was an amazing, fresh & innovative i...  negative\n",
       "4      Encouraged by the positive comments about this...  negative\n",
       "...                                                  ...       ...\n",
       "24995  When I first tuned in on this morning news, I ...  negative\n",
       "24996  I got this one a few weeks ago and love it! It...  positive\n",
       "24997  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "24998  I am a Catholic taught in parochial elementary...  negative\n",
       "24999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('IMDB_dataset.csv')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     25000 non-null  object\n",
      " 1   sentiment  25000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  perform all text preprocessing like lemmatization, tokenizing the text, and removing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(review):\n",
    "     # Removing a  punctuation\n",
    "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize text to words\n",
    "    words = nltk.word_tokenize(review.lower())\n",
    "    \n",
    "    # Removing stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join words back\n",
    "    review = ' '.join(words)\n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess text and assigning it to a new column in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably alltime favorite movie story selfless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>show amazing fresh innovative idea 70 first ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>encouraged positive comment film looking forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>When I first tuned in on this morning news, I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>first tuned morning news thought wow finally e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I got this one a few weeks ago and love it! It...</td>\n",
       "      <td>positive</td>\n",
       "      <td>got one week ago love modern light filled true...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>one expects star trek movie high art fan expec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      I thought this was a wonderful way to spend ti...  positive   \n",
       "1      Probably my all-time favorite movie, a story o...  positive   \n",
       "2      I sure would like to see a resurrection of a u...  positive   \n",
       "3      This show was an amazing, fresh & innovative i...  negative   \n",
       "4      Encouraged by the positive comments about this...  negative   \n",
       "...                                                  ...       ...   \n",
       "24995  When I first tuned in on this morning news, I ...  negative   \n",
       "24996  I got this one a few weeks ago and love it! It...  positive   \n",
       "24997  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "24998  I am a Catholic taught in parochial elementary...  negative   \n",
       "24999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                     preprocessed_review  \n",
       "0      thought wonderful way spend time hot summer we...  \n",
       "1      probably alltime favorite movie story selfless...  \n",
       "2      sure would like see resurrection dated seahunt...  \n",
       "3      show amazing fresh innovative idea 70 first ai...  \n",
       "4      encouraged positive comment film looking forwa...  \n",
       "...                                                  ...  \n",
       "24995  first tuned morning news thought wow finally e...  \n",
       "24996  got one week ago love modern light filled true...  \n",
       "24997  bad plot bad dialogue bad acting idiotic direc...  \n",
       "24998  catholic taught parochial elementary school nu...  \n",
       "24999  one expects star trek movie high art fan expec...  \n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['preprocessed_review'] = ds['review'].apply(preprocessing_text)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform TF-IDF vectorizer for conversion of date into vectors and mapping values of 'sentiment' to 1 and 0  for 'positive' and 'negative' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(ds['preprocessed_review'])\n",
    "y = ds['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Grid search using the random forest classifier, also printing best parameters and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Accuracy: 0.85548\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameter grid for the Random Forest model\n",
    "paramrf = {'n_estimators': [100, 200],\n",
    "             'max_depth': [5, None]}\n",
    "\n",
    "# Defining the Random Forest model\n",
    "modelrf = RandomForestClassifier()\n",
    "\n",
    "# Defining the GridSearchCV object\n",
    "gridrf = GridSearchCV(rf_model, param_grid=rf_params, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "gridrf.fit(x, y)\n",
    "\n",
    "# Print the best parameter settings and accuracy score\n",
    "print('Best Parameters:', gridrf.best_params_)\n",
    "print('Accuracy:', gridrf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform XGBoost to find best parameters and print accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Best Parameters: {'max_depth': 6, 'n_estimators': 100}\n",
      "XGBoost Accuracy: 0.8532399999999999\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameter grid for the XGBoost model\n",
    "paramxg = {'max_depth': [3, 6],\n",
    "              'n_estimators': [50, 100]}\n",
    "\n",
    "# Defining the XGBoost model\n",
    "modelxg = XGBClassifier()\n",
    "\n",
    "# Defining the GridSearchCV object for XGBoost\n",
    "gridxg = GridSearchCV(xgb_model, param_grid=xgb_params, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data for XGBoost\n",
    "gridxg.fit(x, y)\n",
    "\n",
    "# Print the best parameter settings and accuracy score\n",
    "print('XGBoost Best Parameters:', gridxg.best_params_)\n",
    "print('XGBoost Accuracy:', gridxg.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To conclude,to clear all text and making it suitable for the successful prediction output, I have performed Text Preprocessing. To find a best parameters I have used gridsearchcv and implemented 2 classifiers. With the randomforest accuracy is 85.54%  and with the XGBoost it is 85.32% Accuracy. So if we compare both then it can be said that RandomForest giving better accuracy as compare to XGBoost and best parameter for this is 'max_depth:None', 'n_estimator:200'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
